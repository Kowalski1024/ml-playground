{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data loading\n",
    "Downloading the MNIST dataset and dividing it into train, test and validation data loaders."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "\n",
    "    'test'  : torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "\n",
    "    'valid' : torch.utils.data.DataLoader(val_data,\n",
    "                                          batch_size=200,\n",
    "                                          shuffle=False)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model\n",
    "Implementation of ResNet with 2 blocks - Conv2d-BN-ReLU."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "class QuantizableBasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Iniialize a residual block with two convolutions followed by batchnorm layers\n",
    "    \"\"\"\n",
    "    def __init__(self, in_size:int, hidden_size:int, out_size:int, pad:int):\n",
    "        super().__init__()\n",
    "        self.add_relu = nn.quantized.FloatFunctional()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_size, hidden_size, kernel_size=3, stride=2, padding=pad)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(hidden_size, out_size, kernel_size=3, stride=2, padding=pad)\n",
    "        self.bn2 = nn.BatchNorm2d(out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.add_relu.add_relu(out, identity)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "class QuantizableResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.res1 = QuantizableBasicBlock(1, 8, 16, 15)\n",
    "        self.res2 = QuantizableBasicBlock(16, 32, 16, 15)\n",
    "        self.conv = nn.Conv2d(16, n_classes, kernel_size=3)\n",
    "        self.bn = nn.BatchNorm2d(n_classes)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.maxpool(self.bn(self.conv(x)))\n",
    "        return x.view(x.size(0), -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, scheduler=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    acc = accuracy(model(xb), yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return acc, loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = QuantizableResNet()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, scheduler=None):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # iterate over data loader object (generator)\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt, scheduler)\n",
    "\n",
    "        model.eval()\n",
    "        # no gradient computation for evaluation mode\n",
    "        with torch.no_grad():\n",
    "            accs, losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        val_acc = np.sum(np.multiply(accs, nums)) / np.sum(nums)\n",
    "\n",
    "        print(\"Epoch:\", epoch+1)\n",
    "        print(\"Loss: \", val_loss)\n",
    "        print(\"Accuracy: \", val_acc)\n",
    "        print()\n",
    "\n",
    "\n",
    "def check_accuracy(model, data_loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "\n",
    "    model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_epochs = 5\n",
    "loss_func = F.cross_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# get model and optimizer\n",
    "model, opt = get_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss:  0.19892429441213608\n",
      "Accuracy:  0.9405999970436096\n",
      "\n",
      "Epoch: 2\n",
      "Loss:  0.14958409801125527\n",
      "Accuracy:  0.9561999905109405\n",
      "\n",
      "Epoch: 3\n",
      "Loss:  0.11511386513710022\n",
      "Accuracy:  0.9667000019550324\n",
      "\n",
      "Epoch: 4\n",
      "Loss:  0.10888380914926529\n",
      "Accuracy:  0.9694000065326691\n",
      "\n",
      "Epoch: 5\n",
      "Loss:  0.09176633350551128\n",
      "Accuracy:  0.9731000077724457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "fit(n_epochs, model, loss_func, opt, loaders['train'], loaders['valid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "torch.save(model, 'model/mnist.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "from torch.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver, HistogramObserver\n",
    "\n",
    "def calibrate(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            model(image)\n",
    "\n",
    "default_qconfig = torch.quantization.qconfig.get_default_qconfig('fbgemm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Post Training Quantization (PTQ)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "'''\n",
    "NOT WORKING\n",
    "\n",
    "def ptq_eager_mode(_model, _qconfig, _dataloader) -> nn.Module:\n",
    "    # copy model\n",
    "    m = copy.deepcopy(_model)\n",
    "    m.eval()\n",
    "\n",
    "    # Fuse modules\n",
    "    torch.quantization.fuse_modules(m.res1, [['conv1', 'bn1', 'relu1'], ['conv2', 'bn2']], inplace=True)\n",
    "    torch.quantization.fuse_modules(m.res2, [['conv1', 'bn1', 'relu1'], ['conv2', 'bn2']], inplace=True)\n",
    "    torch.quantization.fuse_modules(m, [['conv', 'bn']], inplace=True)\n",
    "\n",
    "    # Adding qconfig\n",
    "    m.qconfig = _qconfig\n",
    "    torch.quantization.prepare(m, inplace=True)\n",
    "\n",
    "    # Calibration\n",
    "    calibrate(m, _dataloader)\n",
    "\n",
    "    # Convert\n",
    "    torch.quantization.convert(m, inplace=True)\n",
    "\n",
    "    return m\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from torch.quantization import quantize_fx\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "\n",
    "def ptq_fx_graph_mode(_model, _qconfig, _dataloader) -> nn.Module:\n",
    "    qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "\n",
    "    m = copy.deepcopy(_model)\n",
    "    m.eval()\n",
    "\n",
    "    example_inputs = (next(iter(loaders['test']))[0])\n",
    "    model_prepared = quantize_fx.prepare_fx(m, qconfig_mapping, example_inputs)\n",
    "\n",
    "    calibrate(model_prepared, _dataloader)\n",
    "\n",
    "    return quantize_fx.convert_fx(model_prepared)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Symmetric layer-wise static PTQ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (res1): Module(\n",
      "    (conv1): QuantizedConvReLU2d(1, 8, kernel_size=(3, 3), stride=(2, 2), scale=0.09093476831912994, zero_point=128, padding=(15, 15))\n",
      "    (conv2): QuantizedConv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), scale=0.14593075215816498, zero_point=128, padding=(15, 15))\n",
      "  )\n",
      "  (res2): Module(\n",
      "    (conv1): QuantizedConvReLU2d(16, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.22077931463718414, zero_point=128, padding=(15, 15))\n",
      "    (conv2): QuantizedConv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), scale=0.3543640971183777, zero_point=128, padding=(15, 15))\n",
      "  )\n",
      "  (conv): QuantizedConv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), scale=0.29815182089805603, zero_point=128)\n",
      "  (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    _input_scale_0 = self._input_scale_0\n",
      "    _input_zero_point_0 = self._input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(x, _input_scale_0, _input_zero_point_0, torch.quint8);  x = _input_scale_0 = _input_zero_point_0 = None\n",
      "    view = quantize_per_tensor.view(-1, 1, 28, 28);  quantize_per_tensor = None\n",
      "    res1_conv1 = self.res1.conv1(view)\n",
      "    res1_conv2 = self.res1.conv2(res1_conv1);  res1_conv1 = None\n",
      "    res1_scale_0 = self.res1_scale_0\n",
      "    res1_zero_point_0 = self.res1_zero_point_0\n",
      "    add_relu = torch.ops.quantized.add_relu(res1_conv2, view, res1_scale_0, res1_zero_point_0);  res1_conv2 = view = res1_scale_0 = res1_zero_point_0 = None\n",
      "    res2_conv1 = self.res2.conv1(add_relu)\n",
      "    res2_conv2 = self.res2.conv2(res2_conv1);  res2_conv1 = None\n",
      "    res2_scale_0 = self.res2_scale_0\n",
      "    res2_zero_point_0 = self.res2_zero_point_0\n",
      "    add_relu_1 = torch.ops.quantized.add_relu(res2_conv2, add_relu, res2_scale_0, res2_zero_point_0);  res2_conv2 = add_relu = res2_scale_0 = res2_zero_point_0 = None\n",
      "    conv = self.conv(add_relu_1);  add_relu_1 = None\n",
      "    dequantize_8 = conv.dequantize();  conv = None\n",
      "    maxpool = self.maxpool(dequantize_8);  dequantize_8 = None\n",
      "    size = maxpool.size(0)\n",
      "    view_1 = maxpool.view(size, -1);  maxpool = size = None\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    quantize_per_tensor_9 = torch.quantize_per_tensor(view_1, _scale_1, _zero_point_1, torch.quint8);  view_1 = _scale_1 = _zero_point_1 = None\n",
      "    dequantize_9 = quantize_per_tensor_9.dequantize();  quantize_per_tensor_9 = None\n",
      "    return dequantize_9\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model/mnist.pt')\n",
    "\n",
    "qconfig = torch.quantization.QConfig(\n",
    "    activation=HistogramObserver.with_args(qscheme=torch.per_tensor_symmetric, dtype=torch.quint8),\n",
    "    weight=MinMaxObserver.with_args(qscheme=torch.per_tensor_symmetric, dtype=torch.qint8)\n",
    ")\n",
    "\n",
    "ptq_symmetric_model = ptq_fx_graph_mode(model, qconfig, loaders['valid'])\n",
    "print(ptq_symmetric_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Asymmetric layer-wise static PTQ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (res1): Module(\n",
      "    (conv1): QuantizedConvReLU2d(1, 8, kernel_size=(3, 3), stride=(2, 2), scale=0.04546738415956497, zero_point=0, padding=(15, 15))\n",
      "    (conv2): QuantizedConv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), scale=0.14294318854808807, zero_point=125, padding=(15, 15))\n",
      "  )\n",
      "  (res2): Module(\n",
      "    (conv1): QuantizedConvReLU2d(16, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.11038965731859207, zero_point=0, padding=(15, 15))\n",
      "    (conv2): QuantizedConv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), scale=0.3355857729911804, zero_point=135, padding=(15, 15))\n",
      "  )\n",
      "  (conv): QuantizedConv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), scale=0.20874696969985962, zero_point=73)\n",
      "  (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    _input_scale_0 = self._input_scale_0\n",
      "    _input_zero_point_0 = self._input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(x, _input_scale_0, _input_zero_point_0, torch.quint8);  x = _input_scale_0 = _input_zero_point_0 = None\n",
      "    view = quantize_per_tensor.view(-1, 1, 28, 28);  quantize_per_tensor = None\n",
      "    res1_conv1 = self.res1.conv1(view)\n",
      "    res1_conv2 = self.res1.conv2(res1_conv1);  res1_conv1 = None\n",
      "    res1_scale_0 = self.res1_scale_0\n",
      "    res1_zero_point_0 = self.res1_zero_point_0\n",
      "    add_relu = torch.ops.quantized.add_relu(res1_conv2, view, res1_scale_0, res1_zero_point_0);  res1_conv2 = view = res1_scale_0 = res1_zero_point_0 = None\n",
      "    res2_conv1 = self.res2.conv1(add_relu)\n",
      "    res2_conv2 = self.res2.conv2(res2_conv1);  res2_conv1 = None\n",
      "    res2_scale_0 = self.res2_scale_0\n",
      "    res2_zero_point_0 = self.res2_zero_point_0\n",
      "    add_relu_1 = torch.ops.quantized.add_relu(res2_conv2, add_relu, res2_scale_0, res2_zero_point_0);  res2_conv2 = add_relu = res2_scale_0 = res2_zero_point_0 = None\n",
      "    conv = self.conv(add_relu_1);  add_relu_1 = None\n",
      "    dequantize_8 = conv.dequantize();  conv = None\n",
      "    maxpool = self.maxpool(dequantize_8);  dequantize_8 = None\n",
      "    size = maxpool.size(0)\n",
      "    view_1 = maxpool.view(size, -1);  maxpool = size = None\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    quantize_per_tensor_9 = torch.quantize_per_tensor(view_1, _scale_1, _zero_point_1, torch.quint8);  view_1 = _scale_1 = _zero_point_1 = None\n",
      "    dequantize_9 = quantize_per_tensor_9.dequantize();  quantize_per_tensor_9 = None\n",
      "    return dequantize_9\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model/mnist.pt')\n",
    "\n",
    "qconfig = torch.quantization.QConfig(\n",
    "    activation=HistogramObserver.with_args(qscheme=torch.per_tensor_affine, dtype=torch.quint8),\n",
    "    weight=MinMaxObserver.with_args(qscheme=torch.per_tensor_affine, dtype=torch.qint8)\n",
    ")\n",
    "\n",
    "ptq_asymmetric_model = ptq_fx_graph_mode(model, qconfig, loaders['valid'])\n",
    "print(ptq_asymmetric_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without quantization\n",
      "Got 9774 / 10000 with accuracy 97.74\n",
      "\n",
      "Symmetric layer-wise static PTQ\n",
      "Got 9755 / 10000 with accuracy 97.55\n",
      "\n",
      "Asymmetric layer-wise static PTQ\n",
      "Got 9685 / 10000 with accuracy 96.85\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model/mnist.pt')\n",
    "\n",
    "print('Without quantization')\n",
    "check_accuracy(model, loaders['test'])\n",
    "print('\\nSymmetric layer-wise static PTQ')\n",
    "check_accuracy(ptq_symmetric_model, loaders['test'])\n",
    "print('\\nAsymmetric layer-wise static PTQ')\n",
    "check_accuracy(ptq_asymmetric_model, loaders['test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}