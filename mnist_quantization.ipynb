{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data loading\n",
    "Downloading the MNIST dataset and dividing it into train, test and validation data loaders."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "\n",
    "    'test'  : torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "\n",
    "    'valid' : torch.utils.data.DataLoader(val_data,\n",
    "                                          batch_size=200,\n",
    "                                          shuffle=False)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model\n",
    "Implementation of ResNet with 2 blocks - Conv2d-BN-ReLU."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.models.quantization.resnet import QuantizableBasicBlock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Iniialize a residual block with two convolutions followed by batchnorm layers\n",
    "    \"\"\"\n",
    "    def __init__(self, in_size:int, hidden_size:int, out_size:int, pad:int):\n",
    "        super().__init__()\n",
    "        self.add_relu = nn.quantized.FloatFunctional()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_size, hidden_size, kernel_size=3, stride=2, padding=pad)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(hidden_size, out_size, kernel_size=3, stride=2, padding=pad)\n",
    "        self.bn2 = nn.BatchNorm2d(out_size)\n",
    "\n",
    "    def convblock(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.add_relu.add_relu(out, identity)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(x + self.convblock(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.res1 = BasicBlock(1, 8, 16, 15)\n",
    "        self.res2 = BasicBlock(16, 32, 16, 15)\n",
    "        self.conv = nn.Conv2d(16, n_classes, kernel_size=3)\n",
    "        self.batchnorm = nn.BatchNorm2d(n_classes)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.maxpool(self.batchnorm(self.conv(x)))\n",
    "        return x.view(x.size(0), -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, scheduler=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    acc = accuracy(model(xb), yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return acc, loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ResNet()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    return model, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, scheduler=None):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # iterate over data loader object (generator)\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt, scheduler)\n",
    "\n",
    "        model.eval()\n",
    "        # no gradient computation for evaluation mode\n",
    "        with torch.no_grad():\n",
    "            accs, losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "\n",
    "        #NOTE: important to multiply with batch size and sum over values\n",
    "        #      to account for varying batch sizes\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        val_acc = np.sum(np.multiply(accs, nums)) / np.sum(nums)\n",
    "\n",
    "        print(\"Epoch:\", epoch+1)\n",
    "        print(\"Loss: \", val_loss)\n",
    "        print(\"Accuracy: \", val_acc)\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "bs=64 #128\n",
    "lr=0.01\n",
    "n_epochs = 5\n",
    "loss_func = F.cross_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# get model and optimizer\n",
    "model, opt = get_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss:  0.12025187499821186\n",
      "Accuracy:  0.9626999950408935\n",
      "\n",
      "Epoch: 2\n",
      "Loss:  0.09123557083308696\n",
      "Accuracy:  0.9728000104427338\n",
      "\n",
      "Epoch: 3\n",
      "Loss:  0.08082188189029693\n",
      "Accuracy:  0.9752000105381012\n",
      "\n",
      "Epoch: 4\n",
      "Loss:  0.07578884046524763\n",
      "Accuracy:  0.9766000139713288\n",
      "\n",
      "Epoch: 5\n",
      "Loss:  0.07517584595829248\n",
      "Accuracy:  0.9769000101089478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "fit(n_epochs, model, loss_func, opt, loaders['train'], loaders['valid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/mnist.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from torch.quantization.observer import MinMaxObserver\n",
    "\n",
    "my_qconfig = torch.quantization.QConfig(\n",
    "    activation=MinMaxObserver.with_args(qscheme=torch.per_tensor_symmetric, dtype=torch.qint8),\n",
    "    weight=MinMaxObserver.with_args(qscheme=torch.per_tensor_symmetric, dtype=torch.qint8)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "model_with_stubs = nn.Sequential(\n",
    "    torch.quantization.QuantStub(),\n",
    "    model,\n",
    "    torch.quantization.DeQuantStub()\n",
    ")\n",
    "\n",
    "model_with_stubs.qconfig = my_qconfig\n",
    "qmodel = torch.quantization.prepare(model_with_stubs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    for xb, yb in loaders['valid']:\n",
    "        qmodel(xb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=1.0)\n",
      "  )\n",
      "  (1): ResNet(\n",
      "    (res1): ResBlock(\n",
      "      (conv1): Conv2d(\n",
      "        1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(15, 15)\n",
      "        (activation_post_process): MinMaxObserver(min_val=-1.8065515756607056, max_val=1.6178522109985352)\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(15, 15)\n",
      "        (activation_post_process): MinMaxObserver(min_val=-15.812700271606445, max_val=16.616336822509766)\n",
      "      )\n",
      "      (batchnorm1): BatchNorm2d(\n",
      "        8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): MinMaxObserver(min_val=-12.264169692993164, max_val=10.694961547851562)\n",
      "      )\n",
      "      (batchnorm2): BatchNorm2d(\n",
      "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): MinMaxObserver(min_val=-27.85474967956543, max_val=26.247802734375)\n",
      "      )\n",
      "    )\n",
      "    (res2): ResBlock(\n",
      "      (conv1): Conv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(15, 15)\n",
      "        (activation_post_process): MinMaxObserver(min_val=-22.926591873168945, max_val=18.905752182006836)\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(15, 15)\n",
      "        (activation_post_process): MinMaxObserver(min_val=-62.03986358642578, max_val=78.43659973144531)\n",
      "      )\n",
      "      (batchnorm1): BatchNorm2d(\n",
      "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): MinMaxObserver(min_val=-49.220375061035156, max_val=42.24079895019531)\n",
      "      )\n",
      "      (batchnorm2): BatchNorm2d(\n",
      "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): MinMaxObserver(min_val=-68.92694854736328, max_val=78.2296371459961)\n",
      "      )\n",
      "    )\n",
      "    (conv): Conv2d(\n",
      "      16, 10, kernel_size=(3, 3), stride=(1, 1)\n",
      "      (activation_post_process): MinMaxObserver(min_val=-42.3624382019043, max_val=152.71084594726562)\n",
      "    )\n",
      "    (batchnorm): BatchNorm2d(\n",
      "      10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=-20.47862434387207, max_val=46.33622741699219)\n",
      "    )\n",
      "    (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "  )\n",
      "  (2): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(qmodel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Weight observer must have a dtype of qint8",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mqmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:535\u001B[0m, in \u001B[0;36mconvert\u001B[1;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inplace:\n\u001B[0;32m    534\u001B[0m     module \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(module)\n\u001B[1;32m--> 535\u001B[0m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    536\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    537\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remove_qconfig:\n\u001B[0;32m    539\u001B[0m     _remove_qconfig(module)\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:573\u001B[0m, in \u001B[0;36m_convert\u001B[1;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, mod \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39mnamed_children():\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;66;03m# both fused modules and observed custom modules are\u001B[39;00m\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# swapped as one unit\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    572\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[1;32m--> 573\u001B[0m         \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# inplace\u001B[39;49;00m\n\u001B[0;32m    574\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    575\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:573\u001B[0m, in \u001B[0;36m_convert\u001B[1;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, mod \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39mnamed_children():\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;66;03m# both fused modules and observed custom modules are\u001B[39;00m\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# swapped as one unit\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    572\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[1;32m--> 573\u001B[0m         \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# inplace\u001B[39;49;00m\n\u001B[0;32m    574\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    575\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:575\u001B[0m, in \u001B[0;36m_convert\u001B[1;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    572\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[0;32m    573\u001B[0m         _convert(mod, mapping, \u001B[38;5;28;01mTrue\u001B[39;00m,  \u001B[38;5;66;03m# inplace\u001B[39;00m\n\u001B[0;32m    574\u001B[0m                  is_reference, convert_custom_config_dict)\n\u001B[1;32m--> 575\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m \u001B[43mswap_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_module_class_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    578\u001B[0m     module\u001B[38;5;241m.\u001B[39m_modules[key] \u001B[38;5;241m=\u001B[39m value\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:608\u001B[0m, in \u001B[0;36mswap_module\u001B[1;34m(mod, mapping, custom_module_class_mapping)\u001B[0m\n\u001B[0;32m    606\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m qmod\u001B[38;5;241m.\u001B[39mfrom_float(mod, weight_qparams)\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 608\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m \u001B[43mqmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_float\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    609\u001B[0m     swapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m swapped:\n\u001B[0;32m    612\u001B[0m     \u001B[38;5;66;03m# Preserve module's pre forward hooks. They'll be called on quantized input\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:474\u001B[0m, in \u001B[0;36mConv2d.from_float\u001B[1;34m(cls, mod)\u001B[0m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_float\u001B[39m(\u001B[38;5;28mcls\u001B[39m, mod):\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \n\u001B[0;32m    470\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    471\u001B[0m \u001B[38;5;124;03m        mod (Module): a float module, either produced by torch.ao.quantization\u001B[39;00m\n\u001B[0;32m    472\u001B[0m \u001B[38;5;124;03m          utilities or provided by the user\u001B[39;00m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ConvNd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_float\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmod\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:242\u001B[0m, in \u001B[0;36m_ConvNd.from_float\u001B[1;34m(cls, mod)\u001B[0m\n\u001B[0;32m    240\u001B[0m         mod \u001B[38;5;241m=\u001B[39m mod[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    241\u001B[0m     weight_post_process \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39mqconfig\u001B[38;5;241m.\u001B[39mweight()\n\u001B[1;32m--> 242\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_qconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation_post_process\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_post_process\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python venv\\ML\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:202\u001B[0m, in \u001B[0;36m_ConvNd.get_qconv\u001B[1;34m(cls, mod, activation_post_process, weight_post_process)\u001B[0m\n\u001B[0;32m    200\u001B[0m     weight_post_process \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39mqconfig\u001B[38;5;241m.\u001B[39mweight()\n\u001B[0;32m    201\u001B[0m weight_post_process(mod\u001B[38;5;241m.\u001B[39mweight)\n\u001B[1;32m--> 202\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m weight_post_process\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mqint8, \\\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeight observer must have a dtype of qint8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    204\u001B[0m qweight \u001B[38;5;241m=\u001B[39m _quantize_weight(mod\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mfloat(), weight_post_process)\n\u001B[0;32m    205\u001B[0m \u001B[38;5;66;03m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001B[39;00m\n",
      "\u001B[1;31mAssertionError\u001B[0m: Weight observer must have a dtype of qint8"
     ]
    }
   ],
   "source": [
    "torch.quantization.convert(qmodel, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}